# -*- coding: utf-8 -*-
"""Amazon Electronic Recommender System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dIwg-Xtyo3MZdjwSPSssrjgMtbZSyvAT

# Amazon Electronic Recommender System

# About

Proyek ini akan menganalisa dataset produk amazon dan membuat model yang dapat merekomendasikan produk tertentu ke user dengan *Collaborative Filtering*.

# Import Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scipy as sp
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

from sklearn.preprocessing import LabelEncoder
from textblob import TextBlob
from wordcloud import WordCloud

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score
from sklearn.metrics.pairwise import cosine_similarity

# this is for jupyter notebook to show the plot in the notebook itself instead of opening a new window
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

# Run this cell and select the kaggle.json file downloaded
# from the Kaggle account settings page.
from google.colab import files
files.upload()

# Let's make sure the kaggle.json file is present.
!ls -lha kaggle.json

# Commented out IPython magic to ensure Python compatibility.
# The Kaggle API client expects this file to be in ~/.kaggle,
# so move it there.
# %mkdir -p ~/.kaggle
# %cp kaggle.json ~/.kaggle/

# This permissions change avoids a warning on Kaggle tool startup.
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d karkavelrajaj/amazon-sales-dataset

!unzip amazon-sales-dataset.zip -d .

"""# Data Loading"""

data = pd.read_csv('amazon.csv')
pd.set_option('display.max_columns', None)
data

"""Output kode di atas memberikan informasi sebagai berikut:

- Terdapat 1465 baris dalam dataset.
- Terdapat 16 kolom yaitu: product_id, product_name, category, discounted_price, actual_price, discount_percentage, rating, rating_count, about_product, user_id, user_name, review_id, review_title, review_content, img_link, product_link.

# Data Understanding

## Informasi dataset
"""

data.info()

"""Dari output terlihat bahwa sebagian besar dari kolom tersebut merupakan objek, ini informasi yang kurang tepat dikarenakan beberapa kolom yang seharusnya bernilai bukan objek / string seperti pada kolom `discounted_price`, `actual_price`, `discount_percentage`, `rating`, dan `rating_count`.

**Mengubah data kolom yang dengan tipe data yang  seharusnya**
"""

data['discounted_price'] = data['discounted_price'].str.replace("₹",'')
data['discounted_price'] = data['discounted_price'].str.replace(",",'')
data['discounted_price'] = data['discounted_price'].astype('float64')

data['actual_price'] = data['actual_price'].str.replace("₹",'')
data['actual_price'] = data['actual_price'].str.replace(",",'')
data['actual_price'] = data['actual_price'].astype('float64')

data['discount_percentage'] = data['discount_percentage'].str.replace('%','').astype('float64') / 100

"""## Null Check"""

print(data.isna().sum())
data.loc[data.rating_count.isnull(),['rating_count']]

# Remove rows with missing values in the rating_count column
data.dropna(subset=['rating_count'], inplace=True)
print(data.isnull().sum())

# Finding unusual string in rating column
data['rating'].value_counts()

"""Terdapat nilai yang aneh di antara rating 2.0 dengan 2.3"""

# The rating column has a value with an incorrect character, so we will exclude
# the row to obtain a clean dataset.
count = data['rating'].str.contains('\|').sum()
print(f"Total rows containing '|' on 'rating': {count}")
data = data[data['rating'].apply(lambda x: '|' not in str(x))]
count = data['rating'].str.contains('\|').sum()
print(f"Total rows containing '|' on 'rating': {count}")

"""Maka rating dapat kita ubah sesuai dengan tipe data yang seharusnya."""

data['rating'] = data['rating'].astype(str).str.replace(',','').astype('float64')
data['rating_count'] = data['rating_count'].astype(str).str.replace(',', '').astype('float64')

data.info()

"""## Duplication Check"""

data.duplicated().any()

any_duplicates = data.duplicated(subset=['product_id', 'product_name', 'category', 'discounted_price',
       'actual_price', 'discount_percentage', 'rating', 'rating_count',
       'about_product', 'user_id', 'user_name', 'review_id', 'review_title',
       'review_content', 'img_link', 'product_link']).any()
any_duplicates

"""tidak ada data yang duplikat

## Rating Weight

Membuat `rating_weighted` akan menguntungkan karena juga melibatkan berapa orang yang memberikan rating tersebut. Hal ini dapat membantu mengidentifikasi produk dengan kepuasan pelanggan tinggi dan banyak penilaian positif dibandingkan dengan produk dengan peringkat rata-rata tinggi tetapi sedikit penilai.
"""

data['rating_weighted'] = data['rating'] * data['rating_count']
data.rating_weighted

"""## Pemisahan Kategori

Pemisahan kategori akan memudahkan dalam analisis dan visualisasi
"""

# Sub category in the last section
data['sub_category'] = data['category'].astype(str).str.split('|').str[-1]

# Main category is the general category
data['main_category'] = data['category'].astype(str).str.split('|').str[0]
data[['main_category','sub_category']]

"""Pemisahan kategori akan memudahkan dalam menganalisa data

## Explanatory Data Analysis (EDA)

### Distribusi produk di setiap kategori
"""

# First step
# Analyzing distribution of products by main category
main_category_counts = data['main_category'].value_counts()[:30] # Select only the top 30 main categories.
plt.bar(range(len(main_category_counts)), main_category_counts.values)
plt.ylabel('Number of Products')
plt.title('Distribution of Products by Main Category (Top 30)')
plt.xticks(range(len(main_category_counts)), '') # hide X-axis labels
plt.show()

# Top 30 main categories
top_main_categories = pd.DataFrame({'Main Category': main_category_counts.index, 'Number of Products': main_category_counts.values})
print('Top 30 main categories:')
print(top_main_categories.to_string(index=False))

"""Dari output diatas, dapat diperoleh beberapa insight:

- Tiga kategori teratas adalah `Electronics`, `Computer & Accessories`, dan `Home & Kitchen`. Hal ini memperlihatkan barang-barang tersebut adalah yang terpopuler di antara pelanggan.
- Jumlah produk di `main categories` lainnya cukup sedikit, menunjukkan bahwa kategori tersebut tidak sepopuler tiga kategori teratas.
- `Office Product`, `Musical Instruments`, `Home Improvement`, `Toys & Games`, `Car & Motorbike` dan `Health & Personal Care` memiliki jumlah produk yang sedikit yang berarti permintaan pada kategori tersebut juga sedikit.
- Secara keseluruhan, data ini dapat membantu pemahaman bisnis mengenai tren pasar dan mengenali peluang menguntungkan untuk perkembangan di kategori tertentu.    
"""

# Analyzing distribution of products by last category
sub_category_counts = data['sub_category'].value_counts()[:30] # Select only the top 30 last categories.
plt.bar(range(len(sub_category_counts)), sub_category_counts.values)
plt.ylabel('Number of Products')
plt.title('Distribution of Products by Sub Category (Top 30)')
plt.xticks(range(len(sub_category_counts)), '') # hide X-axis labels
plt.show()

# Top 30 sub categories
top_sub_categories = pd.DataFrame({'Sub Category': sub_category_counts.index, 'Number of Products': sub_category_counts.values})
print('Top 30 sub categories:')
print(top_sub_categories.to_string(index=False))

"""Dari output di atas dapat diperoleh beberapa insight sebagai berikut:

- Enam subkategori teratas adalah `USB Cabels`, `Smartwatches`, `Smartphones`, `SmartTelevisions`, `In Ear`, dan `RemoteControls`. Subkategori tersebut merupakan yang terpopuler sehingga bisnis mungkin akan berfokus pada produk-produk tersebut.
- Subkategori terpopuler lainnya ada `MixerGrinders`, `HDMICables`, `DryIrons`, `Mice`, dan `InstantWaterHeaters`. Subkategori tersebut kurang populer jika dibandingkan dengan enam teratas, namun masih diminati dan ada kebutuhan dengan produk tersebut.
- Data di atas memperlihatkan keanekaramanan subkategori di 30 teratas meliputi peralatan dapur, barang elektronik rumah, dan aksesoris pribadi. INi memperlihatkan pentingnya untuk menyediakan produk-produk yang bervariasi untuk kebutuhan pelanggan yang berbeda-beda.
- Secara keseluruhan data tersebut membantu bisnis mengenali subkategori yang populer dan mengatur tawaran produk untuk menjangkau permintaan pelanggan. Dengan fokus pada subkategori tersebut akan membantu meningkatkan penjualan.

### Rata-rata rating untuk setiap kategori produk
"""

plt.hist(data['rating'])
plt.xlabel('Rating')
plt.ylabel('Number of Reviews')
plt.title('Distribution of Customer Ratings')
plt.show()

# Create table with values per cluster
bins = [0, 1, 2, 3, 4, 5] # Define bin edges
data['cluster'] = pd.cut(data['rating'], bins=bins, include_lowest=True, labels=['0-1', '1-2', '2-3', '3-4', '4-5'])
table = data['cluster'].value_counts().reset_index().sort_values('index').rename(columns={'index': 'Cluster', 'cluster': 'Number of Reviews'})
print(table)

"""Dari output diatas dapat dilihat bahwa:

- Mayoritas pelanggan memberi rating dari 3-4 dan 4-5, dengan total 1453 ulasan.
- Terdapat peningkatan nyata dalam jumlah ulasan pada rentang 2-3 dibandingkan dengan rentang 0-1 dan 1-2 yang lebih rendah.
- Jumlah ulasan terendah terdapat pada rentang 0-1, yang menunjukkan bahwa mungkin masih ada ruang untuk perbaikan dalam hal kepuasan pelanggan.
- Secara keseluruhan, distribusi peringkat pelanggan menunjukkan bahwa sebagian besar pelanggan puas dengan produk, namun mungkin ada peluang perbaikan untuk meningkatkan jumlah peringkat positif.

### Main Category dengan Rating Tertinggi
"""

# Calculate the top main categories
top = data.groupby(['main_category'])['rating'].mean().sort_values(ascending=False).head(10).reset_index()

# Create a bar plot
plt.bar(top['main_category'], top['rating'])

# Add labels and title
plt.xlabel('main_category')
plt.ylabel('Rating')
plt.title('Top main_category by Rating')

# Rotate x-axis labels
plt.xticks(rotation=90)

# Show the plot
plt.show()
ranking = data.groupby('main_category')['rating'].mean().sort_values(ascending=False).reset_index()
print(ranking)

"""Dari output di atas dapat diperoleh informasi:

- Dapat dilihat kategori utama diurutkan berdasarkan rating rata-ratanya.
- Kategori dengan rating tertinggi adalah `OfficeProducts`, `Toys&Games`, dan `HomeImprovement` dengan rating di atas 4. Ini menyatakan bahwa pelanggan secara umum suka dengan produk yang ditawarkan pada kategori tersebut.
- Di sisi lain, kategori utama dengan rating rendah ada `Car&Motorbike`, `MusicalInstruments`,  dan `Health&PersonalCare` dengan rating di bawah 4. Ini berarti perlu adanya perbaikan untuk dapat memenuhi ekspetasi pelanggan.

### Sub Category dengan Rating Tertinggi
"""

# Calculate the top sub categories
top = data.groupby(['sub_category'])['rating'].mean().sort_values(ascending=False).head(10).reset_index()

# Create a bar plot
plt.bar(top['sub_category'], top['rating'])

# Add labels and title
plt.xlabel('sub_category')
plt.ylabel('Rating')
plt.title('Top sub_category by Rating')

# Rotate x-axis labels
plt.xticks(rotation=90)

# Show the plot
plt.show()
ranking = data.groupby('sub_category')['rating'].mean().sort_values(ascending=False).reset_index()
print(ranking)

"""Berdasarkan output diatas, dapat dilihat bahwa:

- Dari tabel dapat dilihat rating dari sub kategori dari atas hingga bawah.
- Produk "tablet", merupakan subkategori teratas dengan rating 4.6 yang berarti pelanggan puas dengan pembeliannya.
- Namun, subkategori terbawah seperti "Dustcovers" dan "ElectricGrinders", memiliki rating terendah,yang berarti pelanggan tidak begitu puas dengan produk tersebut.
- Wawasan seperti ini dapat membantu bisnis fokus pada peningkatan kualitas produk mereka dan meningkatkan pengalaman pelanggan secara keseluruhan. Penting untuk melacak umpan balik pelanggan untuk mengidentifikasi area yang perlu ditingkatkan dan terus memenuhi kebutuhan dan harapan mereka.

### Produk dengan rating terbanyak tiap kategori
"""

import pandas as pd

top_reviewed_per_category = (
    data.groupby(["category"])
    .apply(lambda x: x.nlargest(10, "rating_weighted"))
    .reset_index(drop=True)
)

top_reviewed_per_category[['main_category','sub_category', 'rating', 'rating_count', 'rating_weighted']].head(10).sort_values(by=['rating_weighted'], ascending=False).reset_index(drop=True)

"""Berdasarkan output dapat dilihat:

- Suatu produk dapat populer dengan kategorinya berdasarkan `jumlah rating` yang banyak, membuat pengguna tertarik dan ingin melihat.
- Daftar produk yang  memiliki `rating di atas 3.5` mengidikasikan pengalaman pengguna yang positif.
- Produk dengan `jumlah review` tertinggi di kategorinya berpotensi menjadi top seller meskipun tanpa melalui data penjualan secara langsung.

### Persentase Diskon dengan Main Category
"""

# sort the means in descending order
mean_discount_by_category = data.groupby('main_category')['discount_percentage'].mean()
mean_discount_by_category = mean_discount_by_category.sort_values(ascending=True)

# create the horizontal bar chart
plt.barh(mean_discount_by_category.index, mean_discount_by_category.values)
plt.title('Discount Percentage by Main Category')
plt.xlabel('Discount Percentage')
plt.ylabel('Main Category')
plt.show()

table = pd.DataFrame({'Main Category': mean_discount_by_category.index, 'Mean Discount Percentage': mean_discount_by_category.values})

print(table)

"""Dari output diskon berdasarkan `Main Category` dapat dilihat bahwa:

- Kategori `Toys&games` memiliki permintaan yang cukup tinggi dimana penjual tidak perlu secara signifikan memberikan diskon untuk penjualan produk di kategori ini.
- `Home&Kitchen` dan `Car&Motorbike` mempunyai rata-rata persentase diskon yang serupa, dengan nilai 40% - 42%. Ini menunjukkan bahwa level kompetisi yang sama dengan sensitivitas harga di kedua kategori tersebut.
- Kategori dengan rata-rata diskon tertinggi adalah `HomeImprovement`, `Computer&Accessories`, dan `Elektronik` dengan nilai 57%, 54%, dan 51%. Ini mengindikasikan bahwa di kategori tersebut memiliki harga sangat sensitif, dan penjual harus lebih aktraktif dalam memberikan diskon untuk dapat berkompetisi lebih efektif.
- Juga menarik untuk dilihat bahwa, `OfficeProducts` dan `Health&PersonalCare` punya rata-rata diskon 12% dan 53%, yang berarti di antara kedua kategori tersebut merupakan rata-rata diskon terendah dan tertinggi. Hal ini menunjukkan bahwa kategori-kategori ini mungkin memiliki tingkat sensitivitas harga tertentu, namun tidak pada tingkat yang sama dengan `HomeImprovement`, `Computers&Accessories`, dan `Electronics`.

### Persentase diskon dengan Sub Category
"""

# sort the means in descending order
mean_discount_by_sub_category = data.groupby('sub_category')['discount_percentage'].mean().head(15)
mean_discount_by_sub_category = mean_discount_by_sub_category.sort_values(ascending=True)

# create the horizontal bar chart
plt.barh(mean_discount_by_sub_category.index, mean_discount_by_sub_category.values)
plt.title('Discount Percentage by Sub Category')
plt.xlabel('Discount Percentage')
plt.ylabel('Sub Category')
plt.show()

table = pd.DataFrame({'Sub Category': mean_discount_by_sub_category.index, 'Mean Discount Percentage': mean_discount_by_sub_category.values})

print(table)

"""Dari output dapat dilihat bahwa:

- Tabel diatas memperlihatkan rata-rata diskon tiap subkategori diurutkan secara mundur.
- Subkategori yang memiliki rata-rata diskon rendah adalah `Basic`, dengan nilai 0.0. Hal ini menyatakan bahwa produk ini adalah produk dengan harga murah dan sederhana, pemberian diskon tidak memberikan efek apa-apa pada produk ini.
- `BatteryChargers`, `3DGlasses`, dan `BasicMobiles` adalah contoh subkategori dengan persentase diskon rata-rata sedang, dengan nilai antara 0.18 dan 0.25. Hal ini menunjukkan bahwa produk-produk ini mungkin sensitif terhadap harga, namun tidak pada tingkat yang sama dengan produk-produk dalam subkategori persentase diskon rata-rata yang lebih tinggi.
- `BluetoothSpeakers`, `Bedstand&DeskMounts` dan `BasicCases` adalah contoh subkategori dengan persentase diskon rata-rata tinggi, dengan nilai antara 0.485 dan 0.745. Hal ini menunjukkan bahwa produk-produk ini mungkin lebih sensitif terhadap harga, dan pengecer mungkin perlu menawarkan diskon menarik untuk bersaing secara efektif dalam subkategori ini.
- Subkategori dengan persentase mean diskon tertinggi adalah Subkategori `Adapter` dengan nilai sebesar 0,803333. Hal ini menunjukkan bahwa persaingan untuk produk-produk tersebut tinggi, dan pengecer harus menawarkan diskon yang signifikan untuk menarik pembeli.

### Statistik Deskriptif
"""

unique_products_count = data['product_id'].nunique()
average_price = data['actual_price'].mean()
best_selling_product = data.loc[data['rating_count'].idxmax()]
least_selling_product = data.loc[data['rating_count'].idxmin()]
top_rated_product = data.loc[data['rating'].idxmax()]
lowest_rated_product = data.loc[data['rating'].idxmin()]
most_expensive_product = data.loc[data['actual_price'].idxmax()]
cheapest_product = data.loc[data['actual_price'].idxmin()]
highest_discount_product = data.loc[data['discount_percentage'].idxmax()]
avg_rating_count = data.groupby('product_id')['rating_count'].mean().mean()

df_anl = pd.DataFrame({
    'Pertanyaan': [
        'Jumlah Produk yang unik',
        'Harga rata-rata',
        'Produk terlaris',
        'Produk dengan penjualan paling sedikit',
        'Produk dengan rating tertinggi',
        'Produk dengan rating terendah',
        'Produk termahal',
        'Produk termurah',
        'Produk dengan diskon tertinggi',
        'Jumlah rating rata-rata untuk setiap produk'
    ],
    'Jawaban': [
        unique_products_count,
        average_price,
        best_selling_product['product_name'],
        least_selling_product['product_name'],
        top_rated_product['product_name'],
        lowest_rated_product['product_name'],
        most_expensive_product['product_name'],
        cheapest_product['product_name'],
        highest_discount_product['product_name'],
        avg_rating_count
    ],
    'Harga sebenarnya': [
        None,
        None,
        best_selling_product['actual_price'],
        least_selling_product['actual_price'],
        top_rated_product['actual_price'],
        lowest_rated_product['actual_price'],
        most_expensive_product['actual_price'],
        cheapest_product['actual_price'],
        highest_discount_product['actual_price'],
        None
    ],
    'Rating': [
        None,
        None,
        best_selling_product['rating'],
        least_selling_product['rating'],
        top_rated_product['rating'],
        lowest_rated_product['rating'],
        most_expensive_product['rating'],
        cheapest_product['rating'],
        highest_discount_product['rating'],
        None
    ],
    'Diskon': [
        None,
        None,
        best_selling_product['discount_percentage'],
        least_selling_product['discount_percentage'],
        top_rated_product['discount_percentage'] ,
        lowest_rated_product['discount_percentage'],
        most_expensive_product['discount_percentage'],
        cheapest_product['discount_percentage'],
        highest_discount_product['discount_percentage'],
        None
    ]
})

df_anl

"""Insight:

1. **Rating yang tinggi berkorelasi dengan tingginya penjualan**: Produk dengan rating tertinggi juga menjadi yang best seller.
2. **Rating yang rendah juga berhubungan dengan rendahnya penjualan**: Produk dengan rating terendah juga paling sedikit terjual, dan mereka mendapatkan rating sedikit.
3. **Best seller dan Produk rating teratas sangat menjanjikan**:
4. **Produk dengan harga yang kemahalan diberi rating buruk**: Produk yang memiliki rating kecil dapat menjadi mahal dari harga rata-ratanya.

### Keyword yang populer
"""

product_text = ' '.join(data['about_product'].dropna().values)
wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(product_text)
plt.figure(figsize=(8, 8), facecolor=None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad=0)
plt.show()

"""Kode tersebut menghasilkan awan kata berdasarkan teks deskripsi dalam kumpulan data, agar dapat menganalisis secara visual kata-kata paling umum yang digunakan dalam fitur produk. Semakin besar kata di cloud, semakin sering kata tersebut muncul di kotak deskripsi.

## Sentiment Analysis

Analisis Sentimen atau *opinion mining* adalah bidang *Natural Language Processing* (NLP) yang berfokus pada mengidentifikasi dan mengkategorikan pendapat atau sentimen dalam teks. Tujuannya adalah untuk menentukan sikap masyarakat terhadap suatu topik, layanan, produk atau konteks keseluruhan. Sikap atau sentimen ini dikelompokkan dalam kategori seperti positif, negatif, atau netral.
"""

#Classify sentiment
def sentiment_analysis(text):
    analysis = TextBlob(text)
    #threshold for positive and negative sentiments
    if analysis.sentiment.polarity > 0.1:
        return 'Positive'
    elif analysis.sentiment.polarity < -0.1:
        return 'Negative'
    else:
        return 'Neutral'

#Applying sentiment analysis to the review content
reviews = data['review_content']
reviews_sentiments = reviews.apply(sentiment_analysis)

# Counting the occurrences of each sentiment
sentiment_counts = reviews_sentiments.value_counts()

sentiment_counts.plot(kind='bar', color=['green', 'blue', 'red'], title='Sentiment Analysis of Review Content')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.show()

"""Berdasarkan hasil outputk, dapat dilihat produk yang dijual di amazon secara garis besar ditanggapi dengan review positif oleh para pembeli. Untuk lebih jelasnya dapat dilihat pada kode di bawah ini:"""

# Adding the sentiment labels back to the reviews
data['Sentiment'] = reviews_sentiments

# Finding examples of positive, neutral, and negative sentiments
positive_example = data[data['Sentiment'] == 'Positive'].iloc[0]
neutral_example = data[data['Sentiment'] == 'Neutral'].iloc[0]
negative_example = data[data['Sentiment'] == 'Negative'].iloc[0]

print("Example of sentiment review: ")
example_reviews = pd.DataFrame({
    "Sentiment": ["Positive", "Neutral", "Negative"],
    "Review": [positive_example['review_content'], neutral_example['review_content'], negative_example['review_content']],
    "Rating": [positive_example['rating'], neutral_example['rating'], negative_example['rating']]
})
example_reviews

def wordCloud(words):
    wordCloud = WordCloud(width=800, height=500, background_color='white', random_state=21, max_font_size=120).generate(words)

    plt.figure(figsize=(10, 7))
    plt.imshow(wordCloud, interpolation='bilinear')
    plt.axis('off')

all_words = ' '.join([text for text in data['review_content']])
wordCloud(all_words)

"""### Keyword review dengan rating rendah"""

# Filter the dataframe to include only products with a rating lower than 3
low_rating_df = data[data['rating'] < 3.0]

# Create a string of all the reviews for these products
reviews_text = ' '.join(low_rating_df['review_content'].dropna().values)

# Generate the wordcloud
wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(reviews_text)

# Plot the wordcloud
plt.figure(figsize=(8, 8), facecolor=None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad=0)
plt.show()

"""# Data Preparation

## Seleksi Fitur
"""

product_data = data.drop(['discounted_price', 'actual_price', 'discount_percentage', 'review_id', 'review_title',
                   'user_name', 'img_link', 'product_link'], axis=1)

product_data.info()

product_data['combined_text'] = product_data['product_name'] + ' ' + product_data['category'] + ' ' + product_data['about_product'] +' '+ product_data['review_content']
#Fill null with empty string to avoid issues
product_data['combined_text'] = product_data['combined_text'].fillna('')

"""## Label-Encoding the Sentiment

"""

label_encoder = LabelEncoder()

# Fitting the encoder and transforming the 'Sentiment' column
product_data['Encoded_Sentiment'] = label_encoder.fit_transform(product_data['Sentiment'])

"""# Model Development and Evaluation

## Feature Engineering

TF-IDF (*Term Frequency-Inverse Document Frequency*) adalah metode yang bertujuan mengukur seberapa penting suatu kata terhadap kata-kata lain dalam dokumen. TF-IDF adalah skema representasi yang umum digunakan untuk sistem pengambilan informasi dan ekstraksi dokumen yang relevan dengan kueri tertentu.
"""

#Instantiate TF-IDF Vectorizer
vectorizer = TfidfVectorizer(stop_words='english', max_df=0.95, min_df=2, ngram_range=(1, 1))

vectorizer.fit(product_data['combined_text'])
vectorizer.get_feature_names_out()

#Fit and transform
tfidf_matrix = vectorizer.fit_transform(product_data['combined_text'])
tfidf_matrix.shape

tfidf_matrix.todense()

"""## Content Based Filtering using *Cosine Similarity Matrix*

Cosine similarity digunakan untuk menghitung derajat kesamaan (*similarity degree*) antar produk.

"""

# Compute the cosine similarity matrix based on the tfidf_matrix
cosine_sim = cosine_similarity(tfidf_matrix)

# Print the shape of the cosine similarity matrix to verify
print(cosine_sim.shape)
print()

cosine_sim

def cbf_product_recommendations(id_product, similarity_data=cosine_sim, items=product_data, top_n = 10):
    """
    Rekomendasi product berdasarkan kemiripan dataframe

    Parameter:
    ---
    id_product : tipe data string (str)
                Id produk (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan product sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """

    index = items.index[items.product_id == id_product][0]

    sim_scores = list(enumerate(similarity_data[index]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    return [i[0] for i in sim_scores[1:top_n+1]]

sample_product_id = product_data['product_id'][0]
print(sample_product_id)

product_data.loc[product_data.product_id.eq(sample_product_id), ['product_id', 'product_name', 'category', 'sub_category']]

# Mendapatkan data dengan Content-Based Filtering
product_data.iloc[cbf_product_recommendations(sample_product_id)][['product_name', 'category', 'sub_category']]

"""## Collaborative Filtering using RecommenderNet"""

product_data.info()

df = product_data[['user_id', 'product_id', 'rating', 'rating_count', 'Encoded_Sentiment']]
df

# Mengubah user_id menjadi list tanpa nilai yang sama
user_ids = df['user_id'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding user_id
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke user_id
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke product_id: ', user_encoded_to_user)

# Mengubah product_id menjadi list tanpa nilai yang sama
product_ids = df['product_id'].unique().tolist()
print('list product_id: ', user_ids)

# Melakukan proses encoding product_id
product_to_product_encoded = {x: i for i, x in enumerate(product_ids)}
print('encoded product_id : ', product_to_product_encoded)

# Melakukan proses encoding angka ke product_id
product_encoded_to_product = {i: x for i, x in enumerate(product_ids)}
print('encoded angka ke product_id: ', product_encoded_to_product)

# Mapping userID ke dataframe user
df['user'] = df['user_id'].map(user_to_user_encoded)

# Mapping placeID ke dataframe resto
df['product'] = df['product_id'].map(product_to_product_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah product
num_product = len(product_encoded_to_product)
print(num_product)

# Nilai minimum rating
min_rating = min(df['rating'])

# Nilai maksimal rating
max_rating = max(df['rating'])

print('Number of User: {}, Number of product: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_product, min_rating, max_rating
))

"""Training dan validasi"""

# Mengacak dataset
df = df.sample(frac=1,random_state=42)
df

# Membuat variabel x untuk mencocokkan data user dan product menjadi satu value
x = df[['user', 'product']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_product, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_product = num_product
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.product_embedding = layers.Embedding( # layer embeddings product
        num_product,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.product_bias = layers.Embedding(num_product, 1) # layer embedding product bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    product_vector = self.product_embedding(inputs[:, 1]) # memanggil layer embedding 3
    product_bias = self.product_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_product = tf.tensordot(user_vector, product_vector, 2)

    x = dot_user_product + user_bias + product_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_product, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

df = product_data

user_id = df.user_id.sample(1).iloc[0]
product_bought_by_user = df[df.user_id == user_id]

product_not_bought = df[~df['product_id'].isin(product_bought_by_user.product_id.values)]['product_id']
product_not_bought = list(
    set(product_not_bought)
    .intersection(set(product_to_product_encoded.keys()))
)

product_not_bought = [[product_to_product_encoded.get(x)] for x in product_not_bought]
user_encoder = user_to_user_encoded.get(user_id)
user_product_array = np.hstack(
    ([[user_encoder]] * len(product_not_bought ), product_not_bought)
)
user_product_array

ratings = model.predict(user_product_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_product_ids = [
    product_encoded_to_product.get(product_not_bought[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Product with high ratings from user')
print('----' * 8)

top_product_user = (
    product_bought_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .product_id.values
)

product_df_rows = product_data[product_data['product_id'].isin(top_product_user)]
for row in product_df_rows.itertuples():
    print(row.product_name, ':', row.category, 'with rating', row.rating)

print('----' * 8)
print('Top 10 product recommendation')
print('----' * 8)

recommended_product = product_data[product_data['product_id'].isin(recommended_product_ids)]
recommended_product[['product_name', 'category', 'sub_category', 'rating']]
# for row in recommended_product.itertuples():
    # print(row.product_id, ':', row.category, 'with rating', row.rating)

"""## Hybrid Recommendation System

Fungsi di bawah ini, kita akan membuat **sistem rekomendasi hybrid** dengan menggabungkan ***content-based filtering*** dan ***collaborative filtering***. Pertama, Identifikasi produk serupa untuk setiap id_produk dengan menggunakan *content-based filtering* dengan menggunakan TF-IDF vectorization dari fitur produk untuk menghitung skor *cosine similarity* dengan produk lain. Bagian sistem ini mengenali produk dengan fitur yang serupa. Lalu gunakan *collaborative filtering* dengan menguji rating produk target dan mencari produk lain dengan rating serupa, mengasumsikan produk dengan rating serupa mungkin cocok dengan preferensi user.
"""

def hybrid_recommendation(product_id, content_sim_matrix, products, top_n=10):

    #Content-based filtering
    content_recommendations_idx = cbf_product_recommendations(product_id, similarity_data=content_sim_matrix, items=products, top_n = top_n)

    #Combine content and collaborative recommendations
    #Get indices for collaborative recommendations
    collaborative_recommendations_idx = recommended_product_ids
    # print(collaborative_recommendations_idx)
    #Map indices to product IDs
    collaborative_recommendations_idx = [products.index[products['product_id'] == pid].tolist()[0] for pid in collaborative_recommendations_idx]

    #Combine indices from both methods and remove duplicates
    combined_indices = list(set(content_recommendations_idx + collaborative_recommendations_idx))

    #Get recommended products details
    recommended_products = products.iloc[combined_indices].copy()
    recommended_products = recommended_products[['product_id', 'product_name','category', 'sub_category', 'rating']]

    return recommended_products

sample_product_id = product_data['product_id'][0]
sample_product_name = product_data['product_name'][0]
recommended_products = hybrid_recommendation(sample_product_id, cosine_sim, product_data)
print("Recommendation for user who purchased product \"" + sample_product_name + "\"")
recommended_products.head(10)